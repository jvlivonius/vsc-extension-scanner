# v3.4.1 Technical Debt & Improvements Roadmap

**Purpose:** Address code quality issues and technical debt identified in the v3.4.0 architectural review while maintaining full backward compatibility.

**Target Version:** 3.4.1
**Release Type:** Patch/Minor (refactoring + enhancements, no breaking changes)
**Timeline:** 1-2 weeks after v3.4.0 release
**Estimated Effort:** 8 days (~1.5 weeks)

---

## Executive Summary

Following the comprehensive architectural review of v3.4.0 (documented in `docs/archive/reviews/v3.4-architectural-review.md`), several areas for improvement were identified that should be addressed in v3.4.1:

**Architectural Review Score:** 85/100 (Very Good)
**Release Decision:** ✅ GO for v3.4.0 (technical debt acceptable for initial release)
**Follow-up:** Address HIGH and MEDIUM priority items in v3.4.1

**Key Findings:**
- ✅ **Architecture:** Clean layered design (9/10)
- ✅ **Security:** Strong validation practices (8.5/10)
- ⚠️ **Code Quality:** Some duplication present (8/10)
- ⚠️ **Testing:** Integration test gaps (7.5/10)
- ✅ **Documentation:** Comprehensive (9/10)

**Technical Debt Identified:**

| Priority | Issue | Impact | Effort |
|----------|-------|--------|--------|
| HIGH | Code duplication (~300 lines) | Maintenance burden | 3 days |
| HIGH | Stats thread safety | Race condition risk (low prob) | 1 day |
| HIGH | Cache write robustness | Partial results lost on interrupt | 0.5 days |
| MEDIUM | Architecture documentation gaps | Developer guidance missing | 0.5 days |
| MEDIUM | Integration test coverage | Real API scenarios untested | 2 days |
| MEDIUM | Progress display duplication | DRY violation | 1 day |

---

## HIGH Priority Tasks (Release Blockers for v3.4.1)

### Task 1: Refactor Parallel/Sequential Code Duplication

**Problem:**
- `_scan_extensions()`: 96 lines (sequential mode)
- `_scan_extensions_parallel()`: 203 lines (parallel mode)
- Estimated overlap: ~70% of logic (~300 lines duplicated)

**Impact:**
- Bug fixes require changes in 2 locations
- Testing burden (duplicate coverage needed)
- Higher cognitive load for developers
- DRY principle violation

**Effort:** 3 days

**Implementation Approach:**

Create unified scan function that supports both sequential and parallel modes:

```python
# Proposed: Unified implementation
def _scan_extensions_unified(
    extensions: List[Dict],
    args,
    cache_manager: Optional[CacheManager],
    scan_timestamp: str,
    use_rich: bool,
    quiet: bool
) -> Tuple[List[Dict], Dict]:
    """Unified scan function supporting both sequential and parallel modes."""

    # Determine execution mode
    max_workers = 1  # Sequential by default
    if args.parallel:
        max_workers = min(max(args.workers, 2), 5)  # Parallel: 2-5 workers

    # Common initialization
    stats = _initialize_scan_stats()
    scan_results = []
    results_to_cache = []

    # Shared progress setup
    progress_manager = _setup_progress_display(
        use_rich, quiet, len(extensions), max_workers
    )

    # Execute scans (works for both sequential and parallel)
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {
            executor.submit(
                _scan_single_extension_worker,
                ext, cache_manager, args
            ): ext for ext in extensions
        }

        # Collect results as they complete
        for future in as_completed(futures):
            ext = futures[future]
            result, from_cache, should_cache = future.result()

            # Update results and stats
            scan_results.append(result)
            _update_stats(stats, result, from_cache, ext)

            # Collect for batch caching
            if should_cache:
                results_to_cache.append((ext['id'], ext['version'], result))

            # Update progress
            progress_manager.update(result, from_cache)

    # Batch cache writes in main thread
    _finalize_cache_writes(cache_manager, results_to_cache)

    return scan_results, stats
```

**Benefits:**
- Single source of truth for scan logic
- Sequential mode is just `workers=1`
- Bug fixes apply to both modes automatically
- Easier to understand and maintain
- Reduced code size (~150 lines vs 300 lines)

**Files Affected:**
- `vscode_scanner/scanner.py` (major refactoring)

**Tests:**
- Update existing parallel and sequential tests
- Verify all 84+ existing tests still pass
- No new tests required (functionality unchanged)

**Risks:**
- Medium complexity refactoring
- Requires careful testing to ensure no regressions
- Must maintain exact same behavior for both modes

---

### Task 2: Add Thread-Safe Stats Collection

**Problem:**

Current implementation updates stats dict from multiple threads without locks:

```python
# Current: NOT thread-safe
if result.get('scan_status') == 'success':
    stats['successful_scans'] += 1  # Dict operation, not atomic
    if result.get('vulnerabilities', {}).get('count', 0) > 0:
        stats['vulnerabilities_found'] += 1
else:
    stats['failed_scans'] += 1
```

**Impact:**
- Python dict operations are NOT guaranteed atomic
- Multiple threads incrementing counters simultaneously
- GIL provides some protection but not guaranteed
- Low probability of corruption with simple counters
- Could manifest as incorrect count (rare but possible)

**Effort:** 1 day

**Implementation Approach:**

```python
# Proposed: Thread-safe stats collection
from threading import Lock
from typing import Dict, Any

class ThreadSafeStats:
    """Thread-safe statistics collection for parallel scanning."""

    def __init__(self):
        self._lock = Lock()
        self._stats = {
            'successful_scans': 0,
            'failed_scans': 0,
            'vulnerabilities_found': 0,
            'cached_results': 0,
            'fresh_scans': 0,
            'failed_extensions': []
        }

    def increment(self, key: str, amount: int = 1):
        """Thread-safe increment operation."""
        with self._lock:
            self._stats[key] += amount

    def append_failed(self, ext_info: Dict):
        """Thread-safe list append."""
        with self._lock:
            self._stats['failed_extensions'].append(ext_info)

    def to_dict(self) -> Dict[str, Any]:
        """Get immutable copy of stats."""
        with self._lock:
            return self._stats.copy()

    def get(self, key: str) -> Any:
        """Thread-safe read."""
        with self._lock:
            return self._stats[key]

# Usage in scanner
stats = ThreadSafeStats()
stats.increment('successful_scans')
stats.append_failed({'id': ext['id'], 'error': 'timeout'})
final_stats = stats.to_dict()  # Get dict for display
```

**Benefits:**
- Guaranteed thread safety with Lock
- No race conditions possible
- Future-proof for higher worker counts
- Clean API for stats operations
- Minimal performance overhead (locks only held briefly)

**Files Affected:**
- `vscode_scanner/scanner.py` (add ThreadSafeStats class, update usage)

**Tests:**
- Add concurrency tests (spawn multiple threads updating stats)
- Verify counts are always accurate
- Test concurrent list appends
- Performance test (ensure minimal overhead)

**Risks:**
- Low risk (isolated change)
- Lock contention unlikely with brief operations
- May slightly reduce parallel efficiency (negligible)

---

### Task 3: Add Transactional Cache Writes

**Problem:**

Current implementation has no guarantee of partial saves on interrupt:

```python
# Current: No interrupt handling
if cache_manager and results_to_cache:
    cache_manager.begin_batch()
    for ext_id, version, result in results_to_cache:
        cache_manager.save_result_batch(ext_id, version, result)
    cache_manager.commit_batch()  # May never execute if interrupted
```

**Impact:**
- If user hits Ctrl+C, partial results are lost
- Cache not updated for any scanned extensions
- Wasted API calls on next scan
- Poor user experience (progress not saved)

**Effort:** 0.5 days

**Implementation Approach:**

```python
# Proposed: Transactional cache writes with interrupt handling
def _finalize_cache_writes(
    cache_manager: Optional[CacheManager],
    results_to_cache: List[Tuple[str, str, Dict]]
) -> None:
    """Save scan results to cache with transaction guarantee."""
    if not cache_manager or not results_to_cache:
        return

    try:
        cache_manager.begin_batch()

        for ext_id, version, result in results_to_cache:
            try:
                cache_manager.save_result_batch(ext_id, version, result)
            except Exception as e:
                # Log but continue with other results
                log(f"Cache save failed for {ext_id}: {e}", "WARNING")

    except Exception as e:
        # Critical error in batch operation
        log(f"Batch cache operation failed: {e}", "ERROR")

    finally:
        # ALWAYS commit, even on Ctrl+C or exception
        # Ensures partial results are saved
        try:
            cache_manager.commit_batch()
        except Exception as e:
            # If commit fails, cache may be corrupted
            # Integrity check will catch this on next run
            log(f"Cache commit failed: {e}", "ERROR")
```

**Benefits:**
- Partial results always saved (even on Ctrl+C)
- Better user experience (progress preserved)
- Fault tolerance improved
- No data loss on interrupt
- Graceful degradation (continues even if some saves fail)

**Files Affected:**
- `vscode_scanner/scanner.py` (add try/finally pattern)

**Tests:**
- Test interrupt handling (simulate Ctrl+C)
- Test partial commit success
- Verify cache integrity after interrupts
- Test individual save failures (ensure others still saved)

**Risks:**
- Very low risk
- try/finally is standard pattern
- No behavior change in normal operation
- Only improves interrupt handling

---

## MEDIUM Priority Tasks (Nice-to-Have for v3.4.1)

### Task 4: Document Parallel Scanning Architecture

**Problem:**
- ARCHITECTURE.md missing parallel threading model documentation
- Developers lack guidance on threading design decisions
- Cache write strategy not explained
- Worker isolation pattern not documented

**Impact:**
- Harder for new contributors to understand parallel implementation
- Threading decisions not traceable
- Future modifications may violate design principles

**Effort:** 0.5 days

**Deliverables:**

Add new section to `docs/guides/ARCHITECTURE.md`:

```markdown
## Parallel Scanning Architecture (v3.4+)

### Threading Model

**Worker Isolation Pattern:**
- Each worker thread has isolated `VscanAPIClient` instance
- No shared mutable state between workers
- Thread-safe cache reads (SQLite supports concurrent reads)
- Cache writes serialized in main thread (prevents locking)

**Main Thread Responsibilities:**
1. Cache writes (batch operations, single transaction)
2. Stats aggregation (after all workers complete)
3. Progress display updates (Rich progress bars)

**Worker Thread Responsibilities:**
1. Check cache for existing results (read-only)
2. Scan extension via isolated API client
3. Return result + metadata to main thread

### Cache Write Strategy

**Why Main Thread Only:**

1. **SQLite Limitation:** Connection objects cannot cross threads
2. **Performance:** Single batch transaction more efficient than multiple
3. **Error Recovery:** Easier to handle partial failures in one place
4. **Simplicity:** No need for connection pooling or locks

**Implementation Pattern:**

```python
# Workers: Read + compute, return data
def _scan_single_extension_worker(ext, cache_manager, args):
    # Check cache (read-only, thread-safe)
    cached = cache_manager.get_cached_result(...)
    if cached:
        return cached, True, False

    # Scan (isolated API client)
    result = api_client.scan_extension(...)

    # Return for main thread to cache
    return result, False, True  # (result, from_cache, should_cache)

# Main thread: Collect and batch write
results_to_cache = []
for future in as_completed(futures):
    result, from_cache, should_cache = future.result()
    if should_cache:
        results_to_cache.append((ext_id, version, result))

# Single batch write (main thread only)
cache_manager.begin_batch()
for ext_id, version, result in results_to_cache:
    cache_manager.save_result_batch(ext_id, version, result)
cache_manager.commit_batch()
```

### Performance Characteristics

**Validated via PoC (30 extensions, real API):**

| Workers | Speedup | Success Rate | Recommendation |
|---------|---------|--------------|----------------|
| 1       | 1.00x   | 90.0%        | Sequential     |
| 3       | 4.88x   | 100.0%       | ✅ Default     |
| 5       | 4.27x   | 96.7%        | Advanced users |
| 7       | 4.07x   | 66.7%        | Not recommended |

**Real-World Impact:**
- 66 extensions: 6 minutes → 1.2 minutes (3 workers)
- Near-linear scaling up to 3 workers
- Diminishing returns above 5 workers
- No rate limiting from vscan.dev API (tested up to 7 workers)

### Thread Safety Guarantees

**SQLite Operations:**
- ✅ Cache reads (from workers): Thread-safe (read-only)
- ✅ Cache writes (from main thread): Thread-safe (serialized)
- ✅ No connection sharing across threads

**API Client Operations:**
- ✅ Worker isolation: Each worker has own instance
- ✅ No shared state: Workers operate independently
- ✅ HTTP request delays: Per-worker delay configuration

**Stats Collection:**
- ✅ Thread-safe: Using Lock-protected ThreadSafeStats class (v3.4.1+)
- ✅ No race conditions: All updates protected by lock
```

**Files Affected:**
- `docs/guides/ARCHITECTURE.md` (add ~200 lines)

**Benefits:**
- Clear documentation of threading design
- Easier onboarding for contributors
- Design decisions traceable
- Best practices documented

---

### Task 5: Add Integration Tests

**Problem:**
- Heavy reliance on mocking in unit tests
- No tests with real vscan.dev API
- Config file integration untested
- Missing end-to-end scenarios

**Impact:**
- Integration issues may slip through
- Real API behavior differences not caught
- Config hierarchy not validated in practice

**Effort:** 2 days

**Deliverables:**

**1. Real API Integration Tests (`tests/test_integration.py`):**

```python
class TestRealAPIIntegration(unittest.TestCase):
    """Integration tests using real vscan.dev API."""

    @pytest.mark.integration
    @pytest.mark.slow
    def test_parallel_scan_small_set(self):
        """Test parallel scan with 3 real extensions."""
        # Use actual vscan.dev API (no mocking)
        # Small extension set to avoid rate limiting

        extensions = [
            "ms-python.python",
            "esbenp.prettier-vscode",
            "dbaeumer.vscode-eslint"
        ]

        result = run_scan(
            extensions_dir=test_extensions_dir,
            parallel=True,
            workers=3,
            quiet=True
        )

        # Verify success
        assert result == 0  # No errors

        # Verify cache was populated
        cache_stats = cache_manager.get_cache_stats()
        assert cache_stats['total_entries'] >= 3

    @pytest.mark.integration
    def test_config_file_parallel_settings(self):
        """Test that config file parallel settings work."""
        # Create test config with parallel=true, workers=5
        config_path = Path.home() / ".vscanrc.test"
        config_path.write_text("""
        [scan]
        parallel = true
        workers = 5
        """)

        # Run scan without CLI args
        result = run_scan(config_path=config_path, quiet=True)

        # Verify 5 workers were used
        # (check logs or stats for worker count)
```

**2. CI/CD Integration (`.github/workflows/test.yml` if exists):**

```yaml
- name: Run unit tests
  run: pytest -v -m "not integration"

- name: Run integration tests (main branch only)
  if: github.ref == 'refs/heads/main'
  run: pytest -v -m integration
  env:
    PYTEST_TIMEOUT: 300  # 5 minute timeout
  # Only run on main to avoid rate limiting in PRs
```

**Test Coverage:**
- Real API parallel scan (3 extensions)
- Config file integration (parallel settings)
- Sequential vs parallel result consistency
- Cache behavior with real data
- Error handling with real API errors

**Files Affected:**
- `tests/test_integration.py` (new file, ~300 lines)
- `.github/workflows/test.yml` (if CI/CD exists)

**Benefits:**
- Catches integration issues early
- Validates real API behavior
- Tests config hierarchy end-to-end
- Builds confidence in parallel implementation

**Risks:**
- May hit rate limits if run too frequently
- Requires network access (CI/CD consideration)
- Slower than unit tests (mark as slow)

---

### Task 6: Extract Progress Display Logic

**Problem:**

Progress display code duplicated between sequential and parallel modes:

- Rich progress: Lines 500-507, 570-582 in scanner.py
- Plain progress: Inline in both functions
- Updates scattered throughout scan loops

**Impact:**
- DRY principle violation (~100 lines duplicated)
- Harder to modify display format
- Inconsistent progress indicators
- Mixing display logic with scan logic

**Effort:** 1 day

**Implementation Approach:**

Create `ScanProgressManager` class in `display.py`:

```python
# vscode_scanner/display.py

class ScanProgressManager:
    """Manages scan progress display for Rich or plain modes."""

    def __init__(self, use_rich: bool, total: int, workers: int = 1):
        """
        Initialize progress manager.

        Args:
            use_rich: Use Rich formatting or plain text
            total: Total number of extensions to scan
            workers: Number of parallel workers
        """
        self.use_rich = use_rich
        self.total = total
        self.workers = workers
        self.completed = 0

        if use_rich:
            self.progress = create_scan_progress()
            worker_info = f"{workers} workers" if workers > 1 else "sequential"
            self.task = self.progress.add_task(
                f"[cyan]Scanning ({worker_info})...",
                total=total
            )

    def update(self, result: Dict, from_cache: bool):
        """Update progress with completed extension."""
        self.completed += 1

        if self.use_rich:
            self.progress.update(self.task, advance=1)
        else:
            # Plain progress
            ext_id = result.get('id', 'unknown')
            cache_str = "⚡ Cached" if from_cache else "🔍 Fresh"
            print(f"[{self.completed}/{self.total}] {ext_id} {cache_str}",
                  file=sys.stderr)

    def __enter__(self):
        """Context manager entry."""
        if self.use_rich:
            self.progress.__enter__()
        return self

    def __exit__(self, *args):
        """Context manager exit."""
        if self.use_rich:
            self.progress.__exit__(*args)

# Usage in scanner.py
with ScanProgressManager(use_rich, len(extensions), max_workers) as progress:
    for future in as_completed(futures):
        result, from_cache, should_cache = future.result()
        progress.update(result, from_cache)
        # ... process result
```

**Benefits:**
- DRY principle applied (single implementation)
- Centralized progress logic in display.py
- Easier to modify display format
- Better separation of concerns
- Context manager pattern for cleanup

**Files Affected:**
- `vscode_scanner/display.py` (add ScanProgressManager class)
- `vscode_scanner/scanner.py` (use ScanProgressManager)

**Tests:**
- Test Rich mode progress updates
- Test plain mode progress updates
- Test context manager cleanup
- Verify both sequential and parallel modes

**Risks:**
- Low risk (additive change)
- Must ensure both modes still work correctly
- Display format must remain identical

---

## Timeline & Effort Summary

| Priority | Task # | Task Name | Effort | Dependencies |
|----------|--------|-----------|--------|--------------|
| **HIGH** | 1 | Refactor code duplication | 3 days | None |
| **HIGH** | 2 | Thread-safe stats | 1 day | None |
| **HIGH** | 3 | Transactional cache writes | 0.5 days | None |
| **MEDIUM** | 4 | Document parallel architecture | 0.5 days | None |
| **MEDIUM** | 5 | Integration tests | 2 days | None |
| **MEDIUM** | 6 | Extract progress display | 1 day | Task 1 (refactoring) |
| | | **TOTAL** | **8 days** | **(~1.5 weeks)** |

**Development Strategy:**

**Week 1:** HIGH Priority Tasks
- Days 1-3: Task 1 (code refactoring) - **CRITICAL**
- Day 4: Task 2 (thread safety)
- Day 4-5: Task 3 (cache robustness)

**Week 2:** MEDIUM Priority Tasks + Testing
- Days 1-2: Task 5 (integration tests)
- Day 2-3: Task 6 (progress display)
- Day 3: Task 4 (documentation)
- Day 4: Final testing, bug fixes, release prep

---

## Release Strategy

### v3.4.0 Release (Current)

**Status:** Production-ready
- ✅ Parallel scanning feature complete
- ✅ All tests passing (84+ tests)
- ✅ PoC validated (4.88x speedup with 3 workers)
- ✅ Architectural review: 85/100 (Very Good)
- ✅ **Decision: GO for release**

**Known Technical Debt:**
- Code duplication (~300 lines)
- Stats collection not explicitly thread-safe
- No interrupt handling for cache writes
- Documentation gaps (parallel architecture)
- Integration test gaps

**Rationale for Release:**
- Technical debt acceptable for initial release
- Functionality is correct and well-tested
- Performance targets exceeded
- Security validated
- User-facing features complete

---

### v3.4.1 Release (Follow-up)

**Target:** 1-2 weeks after v3.4.0
**Type:** Patch/Minor (no breaking changes)
**Focus:** Code quality, robustness, documentation

**Scope:**
- ✅ **Code Refactoring:** Eliminate duplication
- ✅ **Thread Safety:** Guarantee correctness
- ✅ **Robustness:** Improve fault tolerance
- ✅ **Documentation:** Fill architecture gaps
- ✅ **Testing:** Add integration coverage
- ✅ **Code Quality:** Apply DRY principle

**Compatibility:**
- No breaking changes to CLI
- No breaking changes to configuration
- No breaking changes to API
- All existing tests must pass
- Performance maintained or improved

---

## Success Criteria for v3.4.1

**Code Quality:**
- ✅ Code duplication eliminated (unified scan function)
- ✅ DRY principle applied throughout
- ✅ Function lengths reduced (<150 lines)
- ✅ Clear separation of concerns

**Thread Safety:**
- ✅ Stats collection guaranteed thread-safe (Lock-protected)
- ✅ No race conditions possible
- ✅ Concurrent tests passing

**Robustness:**
- ✅ Cache writes transactional (partial saves on interrupt)
- ✅ Graceful error handling
- ✅ Fault tolerance improved

**Documentation:**
- ✅ Parallel architecture documented (ARCHITECTURE.md)
- ✅ Threading model explained
- ✅ Design decisions traceable
- ✅ Best practices documented

**Testing:**
- ✅ Integration tests added (real API scenarios)
- ✅ All 84+ existing tests passing
- ✅ New concurrency tests passing
- ✅ Interrupt handling tests passing

**Performance:**
- ✅ No performance regression
- ✅ Speedup targets maintained (≥4x with 3 workers)
- ✅ Memory usage stable

**Backward Compatibility:**
- ✅ CLI arguments unchanged
- ✅ Configuration format unchanged
- ✅ Output formats unchanged
- ✅ API signatures unchanged

---

## Post-Release Review

**Architectural Review Completed:** 2025-10-25
**Review Document:** [`docs/archive/reviews/v3.4-architectural-review.md`](../archive/reviews/v3.4-architectural-review.md)
**Reviewer:** Software Architecture & Senior Development Review
**Overall Score:** 85/100 (Very Good)
**Release Decision:** ✅ **GO for v3.4.0 release**

### Review Summary

**Category Scores:**

| Category | Score | Notes |
|----------|-------|-------|
| Architecture | 9/10 | Clean layered design, minor duplication |
| Security | 8.5/10 | Strong validation, minor threading concerns |
| Code Quality | 8/10 | Clean code, good practices, some duplication |
| Testing | 7.5/10 | Good coverage, needs more integration tests |
| Documentation | 9/10 | Excellent docs, missing parallel arch details |
| Maintainability | 8/10 | Generally clean, refactoring recommended |

**Weighted Score:** 85/100

### Key Findings

**Strengths:**
- ✅ Clean layered architecture maintained
- ✅ Thread-safe parallel implementation
- ✅ Strong security practices (path validation, input sanitization)
- ✅ Comprehensive documentation
- ✅ Excellent PoC validation (4.88x speedup)

**Areas for Improvement:**
- ⚠️ Code duplication (~300 lines between sequential/parallel)
- ⚠️ Stats collection not explicitly thread-safe
- ⚠️ Missing transactional cache writes
- ⚠️ Parallel architecture documentation gaps
- ⚠️ Integration test coverage gaps

### Technical Debt Summary

**HIGH Priority (v3.4.1 Release Blockers):**
1. Code duplication (3 days) - Maintenance burden
2. Thread-safe stats (1 day) - Race condition prevention
3. Transactional cache (0.5 days) - Fault tolerance

**MEDIUM Priority (v3.4.1 Nice-to-Have):**
4. Parallel architecture docs (0.5 days) - Developer guidance
5. Integration tests (2 days) - Real API validation
6. Progress display refactoring (1 day) - DRY principle

**LOW Priority (Deferred):**
- Configuration schema v2 migration
- Worker auto-tuning based on CPU cores
- Performance monitoring in verbose mode

### Recommendation

**v3.4.0:** Approved for release (technical debt acceptable)
**v3.4.1:** Address HIGH and MEDIUM priority items within 1-2 weeks
**Future:** LOW priority items deferred to v3.5+

---

## Migration from v3.3

**Note:** Feature 4 (Parallel Scanning) was originally planned for v3.3 but deferred to v3.4 due to:
- Higher complexity than other v3.3 features
- Optional nature (not critical for core UX improvements)
- Need for thorough testing before release
- Time constraints in v3.3 timeline

v3.3 successfully delivered:
- ✅ Feature 1: Extension Directory Configuration
- ✅ Feature 2: Enhanced Verbose Mode
- ✅ Feature 3: Failed Extensions Tracking

---

## Related Documentation

- **[v3.4.0 Release Notes](../archive/summaries/v3.4.0-release-notes.md)** - v3.4.0 release summary
- **[v3.4 Architectural Review](../archive/reviews/v3.4-architectural-review.md)** - Comprehensive architectural analysis
- **[v3.4 PoC Results](../archive/reviews/v3.4-parallel-scan-poc-results.md)** - Proof of concept validation
- **[Architecture Guide](../guides/ARCHITECTURE.md)** - System architecture documentation
- **[Status](STATUS.md)** - Current project status

---

**Document Version:** 1.0
**Status:** Active Planning Document
**Created:** 2025-10-25
**Last Updated:** 2025-10-25
**Next Review:** Before v3.4.1 implementation begins
