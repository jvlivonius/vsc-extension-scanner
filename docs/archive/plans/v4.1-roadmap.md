# Database Optimization Roadmap - Schema v5.0

**Status**: üìã Planning
**Target Version**: v5.0
**Estimated Effort**: ~2.5 hours
**Impact**: -60% storage, -70% code complexity, +30% query performance

---

## Executive Summary

Optimize cache_manager.py to eliminate denormalization anti-pattern, remove unused code, improve performance, and enhance maintainability while preserving 100% test compatibility.

### Current Issues (Schema v4.1)

1. **Denormalization Anti-Pattern**: 32 columns with massive duplication
   - Full JSON blob stored in `scan_result`
   - Same data extracted to 28 additional columns
   - Only 4 columns actually queried, 24 never used
   - Storage bloat: ~3-5x compared to optimal design

2. **Inefficient Indexes**: 6 single-column indexes, 2 never used
   - `idx_security_score` - indexed but never queried
   - `idx_publisher_verified` - indexed but never queried
   - Missing composite indexes for common query patterns

3. **Code Duplication**: 150+ lines duplicated
   - `save_result()` and `save_result_batch()` share identical extraction logic
   - 32 field extractions √ó 2 methods = 64 redundant operations
   - 21 JSON serializations duplicated

4. **Weak Data Types**: No CHECK constraints
   - `risk_level TEXT` - accepts any string (should be enum)
   - No bounds checking on scores/counts
   - Heavy reliance on application-layer validation

5. **Inefficient Stats Query**: Loads all timestamps into memory
   - `get_cache_stats()` fetches all rows (lines 1160-1174)
   - O(n) memory usage for average calculation
   - Should use SQL aggregation

### Research Findings

**Actually Queried Fields** (from code analysis):
- ‚úÖ `extension_id` + `version` - Primary lookup
- ‚úÖ `scanned_at` - Expiration filtering
- ‚úÖ `risk_level` - Statistics grouping
- ‚úÖ `vulnerabilities_count` - Statistics filtering

**Indexed But Never Queried**:
- ‚ùå `security_score` - Index wasted
- ‚ùå `publisher_verified` - Index wasted

**Extracted But Never Used** (24 columns):
- ‚ùå `dependencies_count`, `has_risk_factors`, `installed_at`
- ‚ùå All v4.0 JSON fields (6 columns): `module_risk_levels`, `score_contributions`, `security_notes`
- ‚ùå All v4.0 metadata (7 columns): `installs`, `rating`, `rating_count`, `repository_url`, `license`, `keywords`, `categories`
- ‚ùå All v4.1 security findings (10 columns): `virustotal_details`, `permissions_details`, `ossf_checks`, `ast_findings`, `socket_findings`, `network_endpoints`, `obfuscation_findings`, `sensitive_findings`, `opengrep_findings`, `vscode_engine`

**External Dependencies**: ZERO
- `output_formatter.py` reads from `scan_result` JSON blob only
- `html_report_generator.py` consumes formatted dicts, no direct DB access
- `display.py` works with in-memory results
- No hardcoded column names outside `cache_manager.py`

**Batch Methods Status**: LEGACY CODE
- `begin_batch()`, `save_result_batch()`, `commit_batch()` used in tests only
- Zero production usage (v3.5.4+ uses instant persistence)
- Can be kept for backward compatibility but simplify implementation

---

## Task Order (Optimized for Minimal Effort)

### Phase 1: Preparation & Foundation (No Breaking Changes)
**Goal**: Extract shared logic, prepare for schema changes

#### Task 1.1: Extract Field Extraction Helper ‚è±Ô∏è 15min

**Purpose**: Eliminate 150-line duplication between save methods

**Implementation**:
```python
def _extract_indexed_fields(self, result: Dict[str, Any]) -> Dict[str, Any]:
    """
    Extract only fields used in database indexes/filters.

    Args:
        result: Full scan result dictionary

    Returns:
        Dict with indexed field values (7 fields for v4.1, 4 for v5.0)
    """
    # Extract core indexed fields
    risk_level = result.get("risk_level")

    # Vulnerabilities
    vulnerabilities = result.get("vulnerabilities", {})
    vuln_count = (
        vulnerabilities.get("count", 0)
        if isinstance(vulnerabilities, dict)
        else 0
    )

    # Legacy fields (will be removed in v5.0)
    security_score = result.get("security_score")
    dependencies = result.get("dependencies", {})
    dependencies_count = dependencies.get("total_count", 0)

    metadata = result.get("metadata", {})
    publisher = metadata.get("publisher", {})
    publisher_verified = 1 if publisher.get("verified") else 0

    risk_factors = result.get("risk_factors", [])
    has_risk_factors = 1 if len(risk_factors) > 0 else 0

    installed_at = result.get("installed_at")

    return {
        "risk_level": risk_level,
        "vulnerabilities_count": vuln_count,
        "security_score": security_score,
        "dependencies_count": dependencies_count,
        "publisher_verified": publisher_verified,
        "has_risk_factors": has_risk_factors,
        "installed_at": installed_at,
    }
```

**Changes**:
- Add new method `_extract_indexed_fields()` to `CacheManager` class
- Refactor `save_result()` to use helper (lines 618-692 ‚Üí single function call)
- Refactor `save_result_batch()` to use helper (lines 799-872 ‚Üí single function call)

**Files Modified**:
- `vscode_scanner/cache_manager.py`

**Tests Affected**:
- All existing tests pass unchanged (same behavior, cleaner code)

---

#### Task 1.2: Optimize get_cache_stats() Query ‚è±Ô∏è 10min

**Purpose**: Fix O(n) memory usage in stats calculation

**Current Code** (lines 1160-1174):
```python
# Loads ALL timestamps into memory
cursor.execute("SELECT scanned_at FROM scan_cache")
timestamp_strs = [row[0] for row in cursor.fetchall()]  # O(n) memory

avg_age_days = None
if timestamp_strs:
    ages = []
    for ts_str in timestamp_strs:
        try:
            ts = datetime.fromisoformat(ts_str)
            age_days = (now - ts).total_seconds() / 86400
            ages.append(age_days)
        except (ValueError, TypeError):
            continue
    if ages:
        avg_age_days = round(sum(ages) / len(ages), 1)
```

**Optimized Code**:
```python
# SQLite aggregation (O(1) memory)
cursor.execute("""
    SELECT
        AVG((julianday('now') - julianday(scanned_at)) * 1.0) as avg_age_days
    FROM scan_cache
    WHERE scanned_at IS NOT NULL
""")
row = cursor.fetchone()
avg_age_days = round(row[0], 1) if row and row[0] is not None else None
```

**Benefits**:
- Memory: O(n) ‚Üí O(1)
- Performance: ~50% faster for 1000+ entries
- Handles NULL timestamps gracefully
- Leverages SQLite's optimized aggregation

**Files Modified**:
- `vscode_scanner/cache_manager.py` - `get_cache_stats()` method

**Tests Affected**:
- `tests/test_cache_commands.py` - Verify stats accuracy maintained
- `tests/test_cache_edge_cases.py` - Verify NULL handling

---

### Phase 2: Schema Redesign (v4.1 ‚Üí v5.0)
**Goal**: Clean storage with only queried fields extracted

#### Task 2.1: Define Schema v5.0 ‚è±Ô∏è 20min

**Purpose**: Eliminate unused columns, add data integrity constraints

**New Schema**:
```sql
CREATE TABLE IF NOT EXISTS scan_cache (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    extension_id TEXT NOT NULL,
    version TEXT NOT NULL,
    scan_result TEXT NOT NULL,           -- Full JSON (source of truth)
    scanned_at TIMESTAMP NOT NULL,
    integrity_signature TEXT,

    -- ONLY actively queried fields (4 core fields)
    risk_level TEXT CHECK(risk_level IN ('low', 'medium', 'high', 'critical', 'unknown', NULL)),
    vulnerabilities_count INTEGER DEFAULT 0 CHECK(vulnerabilities_count >= 0),

    -- Legacy fields (kept for backward compatibility, consider deprecation in v6.0)
    security_score INTEGER CHECK(security_score BETWEEN 0 AND 100 OR security_score IS NULL),
    dependencies_count INTEGER DEFAULT 0 CHECK(dependencies_count >= 0),
    publisher_verified BOOLEAN DEFAULT 0 CHECK(publisher_verified IN (0, 1)),
    has_risk_factors BOOLEAN DEFAULT 0 CHECK(has_risk_factors IN (0, 1)),
    installed_at TIMESTAMP,

    UNIQUE(extension_id, version)
)
```

**Changes Summary**:
- **Removed 23 columns** (never queried):
  - v4.0 JSON: `module_risk_levels`, `score_contributions`, `security_notes`
  - v4.0 metadata: `installs`, `rating`, `rating_count`, `repository_url`, `license`, `keywords`, `categories`
  - v4.1 findings: `virustotal_details`, `permissions_details`, `ossf_checks`, `ast_findings`, `socket_findings`, `network_endpoints`, `obfuscation_findings`, `sensitive_findings`, `opengrep_findings`, `vscode_engine`

- **Added CHECK constraints** (data integrity):
  - `risk_level` enum validation
  - `vulnerabilities_count` non-negative
  - `security_score` bounds (0-100)
  - `publisher_verified` boolean
  - `has_risk_factors` boolean

- **Kept 12 columns**:
  - 6 core: `id`, `extension_id`, `version`, `scan_result`, `scanned_at`, `integrity_signature`
  - 4 queried: `risk_level`, `vulnerabilities_count`, `security_score` (legacy), `dependencies_count` (legacy)
  - 3 legacy: `publisher_verified`, `has_risk_factors`, `installed_at`

**Rationale**:
- All removed data still available in `scan_result` JSON blob
- External consumers (output_formatter, HTML reports) read from JSON only
- Reduces storage by 60% (fewer columns, no JSON-as-TEXT duplication)
- CHECK constraints prevent invalid data at database layer

**Files Modified**:
- `vscode_scanner/cache_manager.py` - `_init_database()` method (lines 379-424)

**Tests Affected**:
- All schema-dependent tests auto-pass (cache regenerates on version mismatch)
- `tests/test_cache_integrity.py` - Verify schema version migration
- `tests/test_cache_edge_cases.py` - Verify CHECK constraints work

---

#### Task 2.2: Optimize Indexes ‚è±Ô∏è 10min

**Purpose**: Replace 6 inefficient indexes with 3 composite/covering indexes

**Current Indexes** (v4.1):
```sql
-- 6 single-column indexes (suboptimal)
CREATE INDEX idx_extension ON scan_cache(extension_id, version);  -- Good
CREATE INDEX idx_scanned_at ON scan_cache(scanned_at);             -- Suboptimal
CREATE INDEX idx_risk_level ON scan_cache(risk_level);             -- Suboptimal
CREATE INDEX idx_security_score ON scan_cache(security_score);     -- NEVER QUERIED
CREATE INDEX idx_vulnerabilities ON scan_cache(vulnerabilities_count);  -- Suboptimal
CREATE INDEX idx_publisher_verified ON scan_cache(publisher_verified);  -- NEVER QUERIED
```

**Problems**:
- Query pattern `WHERE extension_id=? AND version=? AND scanned_at>=?` can't use all 3 columns
- `idx_security_score` wastes space (field never in WHERE clause)
- `idx_publisher_verified` wastes space (field never in WHERE clause)
- Statistics queries need multiple index lookups

**New Indexes** (v5.0):
```sql
-- Composite index for primary lookup + age filtering
CREATE INDEX IF NOT EXISTS idx_lookup_with_age
ON scan_cache(extension_id, version, scanned_at DESC);

-- Composite index for statistics queries
CREATE INDEX IF NOT EXISTS idx_risk_stats
ON scan_cache(risk_level, vulnerabilities_count)
WHERE risk_level IS NOT NULL;

-- Partial index for score filtering (future-proofing)
CREATE INDEX IF NOT EXISTS idx_score
ON scan_cache(security_score)
WHERE security_score IS NOT NULL;
```

**Benefits**:
- **idx_lookup_with_age**: Covering index for `get_cached_result()` query
  - Single index lookup instead of 2 (extension + scanned_at)
  - Sorted DESC for efficient `MAX(scanned_at)` queries

- **idx_risk_stats**: Covers `GROUP BY risk_level` + vulnerability filtering
  - Partial index (excludes NULL risk_level) saves space
  - Supports: `WHERE risk_level = 'high' AND vulnerabilities_count > 0`

- **idx_score**: Partial index only for non-NULL scores
  - Future-proofing for score-based filtering
  - 30-50% smaller than full index (many results have NULL scores)

**Performance Impact**:
- Primary lookups: 20-30% faster (composite index)
- Stats queries: 40-50% faster (covering index)
- Index storage: -40% (3 optimized vs 6 redundant)

**Files Modified**:
- `vscode_scanner/cache_manager.py` - `_init_database()` method (lines 437-473)

**Tests Affected**:
- Performance regression tests (verify query speed maintained/improved)

---

#### Task 2.3: Update SCHEMA_VERSION ‚è±Ô∏è 2min

**Purpose**: Trigger auto-regeneration of cache with new schema

**Change**:
```python
# vscode_scanner/_version.py
SCHEMA_VERSION = "5.0"  # Changed from "4.1"
```

**Effect**:
- Next cache access detects version mismatch (4.1 ‚Üí 5.0)
- `cache_manager.py:80-116` removes old cache, creates new schema
- User experience: `[INFO] Cache schema version 4.1 detected. Current version is 5.0. Removing old cache and regenerating...`

**Files Modified**:
- `vscode_scanner/_version.py` (line 9)

**Tests Affected**:
- `tests/test_cache_integrity.py` - `test_schema_version_migration()`

---

### Phase 3: Simplify Save Logic
**Goal**: Use extracted helper, remove duplication

#### Task 3.1: Refactor save_result() ‚è±Ô∏è 15min

**Purpose**: Reduce from 160 lines ‚Üí 40 lines using helper

**Current Code** (lines 593-754):
```python
def save_result(self, extension_id: str, version: str, result: Dict[str, Any]):
    # ... 20 lines of setup ...

    # Extract indexed fields (DUPLICATED 150 LINES)
    risk_level = result_to_store.get("risk_level")
    security_score = result_to_store.get("security_score")
    vulnerabilities = result_to_store.get("vulnerabilities", {})
    vuln_count = vulnerabilities.get("count", 0) if isinstance(vulnerabilities, dict) else 0
    # ... 25 more field extractions ...

    # Serialize JSON fields (DUPLICATED)
    module_risk_levels_json = json.dumps(module_risk_levels) if module_risk_levels else None
    # ... 20 more JSON serializations ...

    # Compute HMAC
    integrity_signature = self._compute_integrity_signature(scan_result_json)

    # INSERT with 32 values
    cursor.execute("""
        INSERT OR REPLACE INTO scan_cache
        (extension_id, version, scan_result, scanned_at, risk_level, security_score, ...)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, (extension_id, version, scan_result_json, scanned_at, risk_level, security_score, ...))
```

**Refactored Code**:
```python
def save_result(self, extension_id: str, version: str, result: Dict[str, Any]):
    """
    Save scan result to cache (v5.0 schema with minimal indexed fields).

    Args:
        extension_id: Extension ID (e.g., "ms-python.python")
        version: Extension version
        result: Scan result dictionary to cache
    """
    # Don't cache failed scans
    if result.get("scan_status") != "success":
        return

    try:
        with self._db_connection() as conn:
            cursor = conn.cursor()

            # Remove cache metadata before storing
            result_to_store = result.copy()
            result_to_store.pop("_cache_hit", None)
            result_to_store.pop("_cached_at", None)

            # Serialize full result
            scan_result_json = json.dumps(result_to_store)
            scanned_at = datetime.now().isoformat()

            # Extract only indexed fields (uses helper from Task 1.1)
            indexed = self._extract_indexed_fields(result_to_store)

            # Compute HMAC signature for integrity checking
            integrity_signature = self._compute_integrity_signature(scan_result_json)

            # Insert with v5.0 schema (12 values instead of 32)
            cursor.execute("""
                INSERT OR REPLACE INTO scan_cache
                (extension_id, version, scan_result, scanned_at, integrity_signature,
                 risk_level, vulnerabilities_count, security_score, dependencies_count,
                 publisher_verified, has_risk_factors, installed_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                extension_id,
                version,
                scan_result_json,
                scanned_at,
                integrity_signature,
                indexed['risk_level'],
                indexed['vulnerabilities_count'],
                indexed['security_score'],
                indexed['dependencies_count'],
                indexed['publisher_verified'],
                indexed['has_risk_factors'],
                indexed['installed_at']
            ))

            conn.commit()

    except (sqlite3.Error, json.JSONDecodeError) as e:
        # Log error but don't fail the scan
        sanitized_error = sanitize_error_message(str(e), context="cache write")
        print(f"Cache write error: {sanitized_error}")
```

**Improvements**:
- 160 lines ‚Üí 40 lines (75% reduction)
- Zero duplication (uses shared helper)
- 32 INSERT values ‚Üí 12 values
- Clearer logic flow
- Same HMAC security
- Better error context

**Files Modified**:
- `vscode_scanner/cache_manager.py` - `save_result()` method (lines 593-754)

**Tests Affected**:
- `tests/test_cache_integrity.py` - HMAC validation, roundtrip tests
- `tests/test_property_cache.py` - Property-based testing (200+ examples)

---

#### Task 3.2: Update save_result_batch() ‚è±Ô∏è 10min

**Purpose**: Apply same refactoring to batch method

**Changes**:
- Replace 150-line extraction (lines 799-872) with `_extract_indexed_fields()` call
- Update INSERT statement to v5.0 schema (12 values instead of 32)
- Keep batch transaction logic unchanged (maintains test compatibility)

**Code Pattern** (same as Task 3.1):
```python
def save_result_batch(self, extension_id: str, version: str, result: Dict[str, Any]):
    # ... batch setup checks ...

    # Use shared extraction helper
    indexed = self._extract_indexed_fields(result_to_store)

    # Simplified INSERT
    self._batch_cursor.execute("""
        INSERT OR REPLACE INTO scan_cache
        (extension_id, version, scan_result, scanned_at, integrity_signature,
         risk_level, vulnerabilities_count, security_score, dependencies_count,
         publisher_verified, has_risk_factors, installed_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, (extension_id, version, scan_result_json, scanned_at, integrity_signature,
          indexed['risk_level'], indexed['vulnerabilities_count'], ...))
```

**Note**: Batch methods are legacy (v3.5.4+ uses instant persistence), but kept for test compatibility.

**Files Modified**:
- `vscode_scanner/cache_manager.py` - `save_result_batch()` method (lines 769-927)

**Tests Affected**:
- `tests/test_transactional_cache.py` - 35 batch operation tests
- `tests/test_cache_edge_cases.py` - Batch error handling

---

### Phase 4: Code Quality Improvements
**Goal**: Fix data type handling, improve maintainability

#### Task 4.1: Add Type Hints to Helper Methods ‚è±Ô∏è 10min

**Purpose**: Improve code clarity and enable static type checking

**Changes**:
```python
from typing import Optional, Dict, Any, List, Tuple, Union

class CacheManager:
    # ... existing code ...

    def _extract_indexed_fields(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Extract only fields used in database indexes/filters.

        Args:
            result: Full scan result dictionary

        Returns:
            Dict with indexed field values (risk_level, vulnerabilities_count, etc.)
        """
        # ... implementation ...

    def _verify_integrity_signature(self, data: str, signature: str) -> bool:
        """
        Verify HMAC-SHA256 signature for cache integrity.

        Args:
            data: JSON string to verify
            signature: Base64-encoded HMAC signature

        Returns:
            True if signature valid, False otherwise
        """
        # ... implementation ...

    def _compute_integrity_signature(self, data: str) -> str:
        """
        Compute HMAC-SHA256 signature for cache integrity.

        Args:
            data: JSON string to sign

        Returns:
            Base64-encoded HMAC signature
        """
        # ... implementation ...
```

**Files Modified**:
- `vscode_scanner/cache_manager.py` - All private methods

**Tests Affected**:
- None (type hints are documentation, don't change behavior)
- If mypy configured: run `mypy vscode_scanner/cache_manager.py`

---

#### Task 4.2: Add Input Validation to save_result() ‚è±Ô∏è 15min

**Purpose**: Fail fast on invalid input, provide clear error messages

**Implementation**:
```python
def save_result(self, extension_id: str, version: str, result: Dict[str, Any]):
    """Save scan result to cache with validation."""

    # Validate scan status
    if result.get("scan_status") != "success":
        return

    # Validate extension_id format (prevent SQL injection, validate format)
    from .utils import validate_extension_id
    if not validate_extension_id(extension_id):
        raise ValueError(f"Invalid extension_id format: {sanitize_string(extension_id)}")

    # Validate version format (basic sanity check)
    if not version or not isinstance(version, str):
        raise ValueError(f"Invalid version: {sanitize_string(str(version))}")

    try:
        with self._db_connection() as conn:
            cursor = conn.cursor()

            # Remove cache metadata
            result_to_store = result.copy()
            result_to_store.pop("_cache_hit", None)
            result_to_store.pop("_cached_at", None)

            # Serialize and validate JSON
            try:
                scan_result_json = json.dumps(result_to_store)
            except (TypeError, ValueError) as e:
                raise ValueError(f"Cannot serialize result to JSON: {sanitize_string(str(e))}")

            # Validate timestamp format
            scanned_at = datetime.now().isoformat()

            # Extract and validate indexed fields
            indexed = self._extract_indexed_fields(result_to_store)

            # Validate extracted field values
            if indexed['vulnerabilities_count'] < 0:
                raise ValueError("vulnerabilities_count cannot be negative")

            if indexed['security_score'] is not None:
                if not (0 <= indexed['security_score'] <= 100):
                    raise ValueError(f"security_score must be 0-100, got {indexed['security_score']}")

            # ... rest of save logic ...

    except (sqlite3.Error, json.JSONDecodeError) as e:
        sanitized_error = sanitize_error_message(str(e), context="cache write")
        print(f"Cache write error: {sanitized_error}")
    except ValueError as e:
        # Validation errors - provide clear feedback
        sanitized_error = sanitize_string(str(e))
        print(f"Cache validation error: {sanitized_error}", file=sys.stderr)
```

**Benefits**:
- Fail fast on invalid input (before database write)
- Clear error messages for debugging
- Leverages CHECK constraints (database layer validation)
- Prevents invalid data from entering cache

**Files Modified**:
- `vscode_scanner/cache_manager.py` - `save_result()` method

**Tests Affected**:
- `tests/test_cache_edge_cases.py` - Add validation tests
- New tests for: negative counts, out-of-bounds scores, invalid extension_id

---

#### Task 4.3: Improve Error Messages ‚è±Ô∏è 10min

**Purpose**: Add context to sanitized errors, provide actionable guidance

**Current Error Handling**:
```python
except sqlite3.Error as e:
    sanitized_error = sanitize_error_message(str(e), context="cache write")
    print(f"Cache write error: {sanitized_error}")
```

**Improved Error Handling**:
```python
except sqlite3.IntegrityError as e:
    # CHECK constraint violations
    if "CHECK constraint failed" in str(e):
        sanitized_error = sanitize_error_message(str(e), context="data validation")
        print(f"[ERROR] Cache validation failed: {sanitized_error}", file=sys.stderr)
        print("[HELP] Check that risk_level is valid and scores are in range 0-100", file=sys.stderr)
    else:
        sanitized_error = sanitize_error_message(str(e), context="cache integrity")
        print(f"[ERROR] Cache integrity error: {sanitized_error}", file=sys.stderr)

except sqlite3.OperationalError as e:
    sanitized_error = sanitize_error_message(str(e), context="cache database")
    print(f"[ERROR] Cache database error: {sanitized_error}", file=sys.stderr)
    print("[HELP] Try clearing cache with: vscan cache clear", file=sys.stderr)

except sqlite3.Error as e:
    sanitized_error = sanitize_error_message(str(e), context="cache write")
    print(f"[ERROR] Cache write error: {sanitized_error}", file=sys.stderr)
```

**Error Categories**:
- `IntegrityError` ‚Üí CHECK constraint violations (data validation)
- `OperationalError` ‚Üí Database locked, disk full, corruption
- `Error` ‚Üí Generic database errors

**Files Modified**:
- `vscode_scanner/cache_manager.py` - All error handling blocks

**Tests Affected**:
- `tests/test_cache_edge_cases.py` - Verify error message clarity

---

### Phase 5: Testing & Validation
**Goal**: Ensure 100% compatibility, no regressions

#### Task 5.1: Run Full Test Suite ‚è±Ô∏è 5min

**Commands**:
```bash
# Full test suite with coverage
pytest tests/ -v --cov=vscode_scanner.cache_manager --cov-report=term-missing

# Security tests (must be 95%+)
python3 tests/test_security.py

# Architecture tests
python3 tests/test_architecture.py
```

**Expected Results**:
- ‚úÖ All 245+ tests pass
- ‚úÖ Cache manager coverage maintained at 87%+
- ‚úÖ Security coverage maintained at 95%+
- ‚úÖ Zero architecture violations

**What to Check**:
- Schema auto-regeneration works (test_cache_integrity.py)
- HMAC validation still passes (test_property_cache.py)
- Batch operations work (test_transactional_cache.py)
- Stats queries accurate (test_cache_commands.py)

**Files Modified**:
- None (validation only)

**Tests Affected**:
- All cache-related tests (18 test files)

---

#### Task 5.2: Integration Testing ‚è±Ô∏è 10min

**Purpose**: Verify real-world behavior with new schema

**Test Scenarios**:
```bash
# 1. Clean cache and scan
rm -rf ~/.vscan/cache.db
./vscan scan --workers 3

# Expected: Schema v5.0 created, HMAC validation works

# 2. Test cache hits
./vscan scan --workers 3

# Expected: Cache hits for all extensions, faster stats query

# 3. Test cache stats
./vscan cache stats

# Expected: Accurate statistics, faster execution

# 4. Test cache clear
./vscan cache clear

# Expected: All entries removed, VACUUM runs if threshold met

# 5. Upgrade scenario (simulate v4.1 ‚Üí v5.0)
# Copy v4.1 cache.db to ~/.vscan/
./vscan scan

# Expected: Auto-detects version mismatch, regenerates with v5.0 schema
```

**What to Verify**:
- Cache hit/miss behavior identical
- Stats command output accurate
- No error messages during normal operation
- Schema migration message shown (v4.1 ‚Üí v5.0)

**Files Modified**:
- None (manual testing)

---

#### Task 5.3: Performance Benchmarking ‚è±Ô∏è 15min

**Purpose**: Verify performance improvements

**Benchmarks**:

1. **Lookup Query Performance**:
```python
# Benchmark script
import time
from vscode_scanner.cache_manager import CacheManager

cache = CacheManager()
extension_id = "ms-python.python"
version = "2024.0.0"

# Warm up
for _ in range(10):
    cache.get_cached_result(extension_id, version)

# Benchmark (1000 lookups)
start = time.perf_counter()
for _ in range(1000):
    cache.get_cached_result(extension_id, version)
end = time.perf_counter()

print(f"Lookup time: {(end - start) / 1000 * 1000:.2f} ms per query")
# Expected v4.1: ~0.8-1.2ms
# Expected v5.0: ~0.5-0.8ms (20-30% faster with composite index)
```

2. **Stats Query Performance**:
```python
# Benchmark get_cache_stats()
start = time.perf_counter()
stats = cache.get_cache_stats()
end = time.perf_counter()

print(f"Stats query time: {(end - start) * 1000:.2f} ms")
# Expected v4.1: ~50-100ms (loads all timestamps)
# Expected v5.0: ~20-40ms (SQL aggregation)
```

3. **Storage Efficiency**:
```bash
# Check database size (1000 cached extensions)
ls -lh ~/.vscan/cache.db

# Expected v4.1: 50-100 MB
# Expected v5.0: 20-40 MB (60% reduction)
```

**Success Criteria**:
- ‚úÖ Lookup queries 20-30% faster (composite index)
- ‚úÖ Stats queries 40-50% faster (SQL aggregation)
- ‚úÖ Database size 60% smaller (fewer columns)

**Files Modified**:
- Create `scripts/benchmark_cache.py` (optional, for documentation)

---

#### Task 5.4: Documentation Update ‚è±Ô∏è 10min

**Purpose**: Document v5.0 changes, migration notes

**CHANGELOG.md Update**:
```markdown
## [5.0.0] - 2025-XX-XX

### Changed - Database Schema Optimization

**Breaking Change**: Cache schema v4.1 ‚Üí v5.0 (auto-regenerates on upgrade)

#### Schema Improvements
- **Eliminated denormalization**: Removed 23 unused columns (only stored, never queried)
- **Added data integrity**: CHECK constraints on risk_level, scores, counts
- **Optimized indexes**: 6 single-column ‚Üí 3 composite indexes (40% smaller, 30% faster)
- **Simplified code**: Reduced save_result() from 160 lines ‚Üí 40 lines (75% reduction)

#### Performance Impact
- Lookup queries: 20-30% faster (composite index coverage)
- Stats queries: 40-50% faster (SQL aggregation vs memory loading)
- Storage: 60% smaller (12 columns vs 32 columns)
- Code duplication: Eliminated 150+ duplicated lines

#### Migration
- **Automatic**: Cache auto-regenerates on version mismatch (ephemeral data)
- **User Impact**: First run after upgrade shows migration message, rescans extensions
- **No Action Required**: Cache philosophy unchanged (regenerate from API)

#### Removed Columns (data still in scan_result JSON)
- v4.0 fields: module_risk_levels, score_contributions, security_notes
- v4.0 metadata: installs, rating, rating_count, repository_url, license, keywords, categories
- v4.1 findings: virustotal_details, permissions_details, ossf_checks, ast_findings,
  socket_findings, network_endpoints, obfuscation_findings, sensitive_findings,
  opengrep_findings, vscode_engine

#### Kept Columns (actively queried)
- Core: extension_id, version, scan_result, scanned_at, integrity_signature
- Queried: risk_level, vulnerabilities_count
- Legacy: security_score, dependencies_count, publisher_verified, has_risk_factors, installed_at

### Fixed
- get_cache_stats() memory efficiency (O(n) ‚Üí O(1) with SQL aggregation)
- Code duplication between save_result() and save_result_batch()
- Missing CHECK constraints for data validation
- Inefficient single-column indexes
```

**Files Modified**:
- `CHANGELOG.md`

---

## Success Criteria

### Functionality ‚úÖ
- [ ] All 245+ tests pass (pytest tests/)
- [ ] HMAC integrity validation works (test_cache_integrity.py)
- [ ] Property-based tests pass (test_property_cache.py - 200+ examples)
- [ ] Batch operations work (test_transactional_cache.py)
- [ ] Cache stats accurate (test_cache_commands.py)
- [ ] Schema auto-regeneration works (v4.1 ‚Üí v5.0 migration)

### Performance ‚úÖ
- [ ] Lookup queries 20-30% faster (composite index)
- [ ] Stats queries 40-50% faster (SQL aggregation)
- [ ] get_cache_stats() uses O(1) memory (no timestamp loading)
- [ ] Database size reduced by 60% (fewer columns)

### Code Quality ‚úÖ
- [ ] save_result() reduced from 160 lines ‚Üí 40 lines (75% reduction)
- [ ] Zero code duplication (shared _extract_indexed_fields helper)
- [ ] Type hints added to helper methods
- [ ] Input validation with clear error messages
- [ ] CHECK constraints prevent invalid data

### Maintainability ‚úÖ
- [ ] Single source of truth (scan_result JSON blob)
- [ ] No external dependencies on schema (verified: zero)
- [ ] Clear upgrade path (ephemeral cache, auto-regenerate)
- [ ] Documentation updated (CHANGELOG)

---

## Risk Mitigation

### Risk: Test Failures Due to Schema Changes
**Likelihood**: Low
**Impact**: Medium
**Mitigation**: Auto-regeneration handles version mismatch (existing pattern since v3.0)
**Rollback**: Revert `_version.py` to v4.1, cache regenerates with old schema

### Risk: Performance Regression on Filtered Queries
**Likelihood**: Very Low
**Impact**: Medium
**Mitigation**: Composite indexes cover all query patterns (verified in research)
**Validation**: Benchmark lookups and stats before/after (Task 5.3)

### Risk: Breaking External Dependencies
**Likelihood**: Zero
**Impact**: High
**Mitigation**: Research confirmed zero external dependencies (all read from scan_result JSON)
**Validation**: Integration testing with output_formatter, HTML reports (Task 5.2)

### Risk: Data Loss on Migration
**Likelihood**: Expected (by design)
**Impact**: Low
**Mitigation**: Cache is ephemeral (can re-scan from API), philosophy unchanged
**User Experience**: Clear migration message, automatic regeneration

### Risk: HMAC Validation Breaks
**Likelihood**: Very Low
**Impact**: High
**Mitigation**: HMAC logic unchanged, only INSERT statement modified
**Validation**: test_cache_integrity.py, test_property_cache.py (95%+ coverage)

---

## Files Modified

### Core Implementation (2 files)
1. **vscode_scanner/cache_manager.py** - Major refactoring
   - Lines changed: ~400-500 (150 removed duplication, 100 simplified INSERT, 50 new validation)
   - New method: `_extract_indexed_fields()`
   - Updated methods: `save_result()`, `save_result_batch()`, `get_cache_stats()`, `_init_database()`

2. **vscode_scanner/_version.py** - Version bump
   - Line 9: `SCHEMA_VERSION = "5.0"`

### Testing (Optional - New Tests)
3. **tests/test_cache_edge_cases.py** - Add validation tests
   - Test negative vulnerabilities_count (should fail CHECK)
   - Test out-of-bounds security_score (should fail CHECK)
   - Test invalid risk_level (should fail CHECK)

### Documentation (1 file)
4. **CHANGELOG.md** - Document v5.0 changes

### Not Modified (Verified Zero Dependencies)
- ‚ùå output_formatter.py (reads from scan_result JSON only)
- ‚ùå html_report_generator.py (consumes formatted dicts)
- ‚ùå display.py (in-memory results only)
- ‚ùå scanner.py (no schema dependencies)
- ‚ùå vscan_api.py (no cache interaction)

---

## Effort Estimates

### Phase 1: Preparation (25 minutes)
- Task 1.1: Extract helper - 15min
- Task 1.2: Optimize stats query - 10min

### Phase 2: Schema Redesign (32 minutes)
- Task 2.1: Define schema v5.0 - 20min
- Task 2.2: Optimize indexes - 10min
- Task 2.3: Update version - 2min

### Phase 3: Save Logic (25 minutes)
- Task 3.1: Refactor save_result() - 15min
- Task 3.2: Update save_result_batch() - 10min

### Phase 4: Code Quality (35 minutes)
- Task 4.1: Type hints - 10min
- Task 4.2: Input validation - 15min
- Task 4.3: Error messages - 10min

### Phase 5: Testing & Validation (40 minutes)
- Task 5.1: Run test suite - 5min
- Task 5.2: Integration testing - 10min
- Task 5.3: Performance benchmarks - 15min
- Task 5.4: Documentation - 10min

**Total: ~2.5 hours** (conservative estimate with testing and documentation)

---

## Rollback Plan

### If Critical Issues Arise

**Quick Rollback** (5 minutes):
```bash
# 1. Revert version to v4.1
git checkout vscode_scanner/_version.py

# 2. Clear cache (triggers regeneration with v4.1 schema)
rm -rf ~/.vscan/cache.db

# 3. Verify
./vscan scan
# Cache recreates with v4.1 schema
```

**Partial Rollback** (10 minutes):
- Keep helper method (_extract_indexed_fields) - no harm
- Keep optimized get_cache_stats() - pure improvement
- Revert only schema changes (SCHEMA_VERSION + _init_database)

**Full Rollback** (15 minutes):
```bash
# Revert entire cache_manager.py
git checkout vscode_scanner/cache_manager.py vscode_scanner/_version.py

# Clear user caches
rm -rf ~/.vscan/cache.db
```

---

## Future Considerations

### Potential v6.0 Improvements
- **Remove legacy fields**: security_score, dependencies_count, publisher_verified, has_risk_factors, installed_at (if never used in production)
- **Pure JSON storage**: Keep only 6 core columns (extension_id, version, scan_result, scanned_at, integrity_signature, risk_level)
- **SQLite JSON functions**: Use `json_extract()` for all filtering (requires SQLite 3.38+)
- **Connection pooling**: If multi-threaded access patterns emerge

### Deprecation Path
1. v5.0: Mark legacy fields as deprecated (documentation)
2. v5.x: Add warning if legacy fields are NULL (detect unused)
3. v6.0: Remove legacy fields (2-3 releases later)

---

## References

- **Current Schema**: cache_manager.py:381-424 (v4.1 schema)
- **Current Indexes**: cache_manager.py:437-473 (6 indexes)
- **Save Logic**: cache_manager.py:593-754 (save_result), 769-927 (save_result_batch)
- **Stats Query**: cache_manager.py:1088-1212 (get_cache_stats)
- **Test Coverage**: 87%+ overall, 95%+ security (18 test files)

---

**Status**: Ready for implementation
**Next Steps**: Review plan ‚Üí Execute tasks in order ‚Üí Validate with full test suite
**Timeline**: ~2.5 hours total (can be split across multiple sessions)
